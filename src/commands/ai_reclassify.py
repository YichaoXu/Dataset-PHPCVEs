"""
AI Reclassify command module for PHP CVE Dataset Collection Tool.

This module provides functionality to reclassify PHP projects based on README content
using AI models.
"""

import os
import time
import json
import csv
import re
import requests
from pathlib import Path
from typing import Optional, Dict, Any, List
import typer
from rich.console import Console

from src.utils.logger import Logger
from src.utils.file_utils import ensure_dir, read_csv_file, write_csv_file
from src.utils.ui import ProgressUI
from src.config import config

console = Console()

def ai_reclassify(
    input_file: Path = typer.Argument(..., help="Path to CSV file generated by collect command"),
    output_file: Path = typer.Option(None, help="Path to output CSV file (default: input file with _reclassified suffix)"),
    api_key: Optional[str] = typer.Option(None, help="API key for AI service"),
    model: str = typer.Option("gpt-3.5-turbo", help="AI model to use for classification"),
    force: bool = typer.Option(False, help="Force reclassification of all projects"),
    verbose: bool = typer.Option(False, help="Enable verbose output")
):
    """
    Reclassify PHP projects based on README content using AI.
    
    This command uses AI to analyze README files from GitHub repositories and
    reclassify PHP projects into more specific categories.
    """
    # Enable verbose logging if requested
    Logger.set_verbose(verbose)
    
    # Start timing
    start_time = time.time()
    
    # Set default output file if not provided
    if not output_file:
        output_file = input_file.with_stem(f"{input_file.stem}_reclassified")
    
    # Create cache directory
    cache_dir = Path(".inter/reclassify")
    ensure_dir(cache_dir)
    
    # Read input file
    Logger.info(f"Reading input file: {input_file}")
    records = read_csv_file(input_file)
    
    if not records:
        Logger.error("No records found in input file")
        raise typer.Exit(1)
    
    # Check API key
    api_key = api_key or config.openai_api_key or config.deepseek_api_key
    if not api_key:
        Logger.error("No API key provided. Set it with --api-key or in the config file.")
        raise typer.Exit(1)
    
    # Process records
    Logger.info(f"Reclassifying {len(records)} projects")
    
    # Track statistics
    cache_hits = 0
    api_calls = 0
    format_errors = 0
    
    # Process each record
    with ProgressUI(len(records), "Reclassifying projects") as progress:
        for i, record in enumerate(records):
            cve_id = record.get("cve_id", f"Unknown-{i}")
            repo = record.get("repository", "")
            
            progress.update(0, f"{cve_id} ({repo})")
            
            try:
                # Skip if no repository
                if not repo:
                    progress.log_warning(f"Skipped {cve_id}: No repository information")
                    progress.update(1, cve_id)
                    continue
                
                # Get README content
                readme = _get_readme_content(repo, cache_dir, force)
                
                if not readme:
                    progress.log_warning(f"Skipped {cve_id}: Could not download README")
                    progress.update(1, cve_id)
                    continue
                
                # Check cache
                repo_id = _get_repo_id(repo)
                cache_file = cache_dir / f"{repo_id}.json"
                if not force and cache_file.exists():
                    try:
                        with open(cache_file, 'r', encoding='utf-8') as f:
                            classification = json.load(f)
                            record["project_type"] = classification.get("project_type", record.get("project_type", "Unknown"))
                            cache_hits += 1
                            progress.log(f"Using cached classification for {repo}: {record['project_type']}")
                            progress.update(1, cve_id)
                            continue
                    except Exception as e:
                        progress.log_warning(f"Cache error for {repo}: {str(e)}")
                
                # Classify using AI
                classification = _classify_with_ai(api_key, readme, repo, model)
                api_calls += 1
                
                if classification:
                    # Save classification to cache
                    try:
                        with open(cache_file, 'w', encoding='utf-8') as f:
                            json.dump(classification, f)
                    except Exception as e:
                        progress.log_warning(f"Failed to save cache for {repo}: {str(e)}")
                    
                    # Update record
                    old_type = record.get("project_type", "Unknown")
                    new_type = classification.get("project_type", old_type)
                    confidence = classification.get("confidence", 0)
                    
                    record["project_type"] = new_type
                    record["classification_confidence"] = confidence
                    record["classification_reasoning"] = classification.get("reasoning", "")
                    
                    progress.log_success(f"Classified {repo}: {old_type} -> {new_type} (confidence: {confidence}%)")
                else:
                    format_errors += 1
                    progress.log_error(f"Failed to classify {repo}")
            except Exception as e:
                progress.log_error(f"Error processing {cve_id}: {str(e)}")
            
            progress.update(1, cve_id)
    
    # Write output file
    Logger.info(f"Writing {len(records)} records to {output_file}")
    write_csv_file(records, output_file)
    
    # Report statistics
    Logger.success(f"Reclassification completed: {api_calls} API calls, {cache_hits} cache hits, {format_errors} format errors")
    
    # Report timing
    elapsed_time = time.time() - start_time
    Logger.info(f"Reclassification completed in {elapsed_time:.2f} seconds")
    
    return len(records)

def _get_repo_id(repo_url: str) -> str:
    """Generate a unique ID for a repository."""
    return repo_url.replace("https://github.com/", "").replace("/", "_")

def _get_readme_content(repo_url: str, cache_dir: Path, force: bool = False) -> Optional[str]:
    """Download README content from GitHub repository."""
    # Extract owner and repo from URL
    repo_path = repo_url.replace("https://github.com/", "")
    parts = repo_path.split('/')
    if len(parts) < 2:
        return None
    
    owner, repo = parts[0], parts[1]
    
    # Check cache
    readme_cache = cache_dir / "readme"
    ensure_dir(readme_cache)
    
    cache_file = readme_cache / f"{owner}_{repo}.txt"
    if not force and cache_file.exists():
        try:
            with open(cache_file, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception:
            pass
    
    # Download README
    try:
        # Try different README filenames
        readme_filenames = ["README.md", "Readme.md", "readme.md", "README.txt", "README"]
        
        for filename in readme_filenames:
            url = f"https://raw.githubusercontent.com/{owner}/{repo}/master/{filename}"
            response = requests.get(url)
            
            if response.status_code == 200:
                content = response.text
                
                # Save to cache
                try:
                    with open(cache_file, 'w', encoding='utf-8') as f:
                        f.write(content)
                except Exception:
                    pass
                
                return content
        
        return None
    except Exception as e:
        Logger.warning(f"Error downloading README for {repo_url}: {str(e)}")
        return None

def _classify_with_ai(api_key: str, readme: str, repo_url: str, model: str) -> Optional[Dict[str, Any]]:
    """Classify a project using AI based on README content."""
    # Prepare prompt
    prompt = f"""
    You are an expert in PHP projects classification. Please analyze the following README content from a PHP project and classify it into one of these categories:
    
    1. Web App - A complete web application
    2. Framework - A PHP framework for building applications
    3. Framework Plugin - A plugin for a PHP framework
    4. Framework Theme - A theme for a PHP framework
    5. Library - A reusable PHP library
    6. CLI App - A command-line PHP application
    7. PHP-SRC - PHP language source code
    
    Repository URL: {repo_url}
    
    README content:
    {readme[:4000]}  # Limit to 4000 chars to avoid token limits
    
    Respond with a JSON object containing:
    {{"project_type": "category_name", "confidence": 0-100, "reasoning": "brief explanation"}}
    """
    
    try:
        # Determine API endpoint based on model
        if "gpt" in model.lower():
            url = "https://api.openai.com/v1/chat/completions"
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}"
            }
            payload = {
                "model": model,
                "messages": [
                    {"role": "system", "content": "You are an expert in PHP project classification."},
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.2
            }
            
            response = requests.post(url, headers=headers, json=payload)
            
            if response.status_code == 200:
                result = response.json()
                content = result["choices"][0]["message"]["content"]
            else:
                Logger.error(f"API error: {response.status_code} - {response.text}")
                return None
                
        elif "deepseek" in model.lower():
            # DeepSeek API implementation
            url = "https://api.deepseek.com/v1/chat/completions"  # Replace with actual endpoint
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}"
            }
            payload = {
                "model": model,
                "messages": [
                    {"role": "system", "content": "You are an expert in PHP project classification."},
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.2
            }
            
            response = requests.post(url, headers=headers, json=payload)
            
            if response.status_code == 200:
                result = response.json()
                content = result["choices"][0]["message"]["content"]
            else:
                Logger.error(f"API error: {response.status_code} - {response.text}")
                return None
        else:
            Logger.error(f"Unsupported model: {model}")
            return None
        
        # Extract JSON from response
        json_match = re.search(r'({.*})', content, re.DOTALL)
        
        if json_match:
            try:
                return json.loads(json_match.group(1))
            except json.JSONDecodeError:
                Logger.warning(f"Failed to parse JSON response: {content}")
                return None
        else:
            Logger.warning(f"No JSON found in response: {content}")
            return None
    except Exception as e:
        Logger.error(f"API error: {str(e)}")
        return None 