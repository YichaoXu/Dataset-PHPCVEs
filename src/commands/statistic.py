"""
Statistic command module for PHP CVE Dataset Collection Tool.

This module provides functionality to generate statistics and visualizations
from the collected data.
"""

import time
import json
from pathlib import Path
from typing import Optional, List
import typer
from rich.console import Console

from src.utils.logger import Logger
from src.utils.file_utils import ensure_dir, read_csv_file, write_json_file
from src.utils.ui import ProgressUI
from src.config import config

try:
    import matplotlib.pyplot as plt
    import pandas as pd
    import seaborn as sns
    HAS_VISUALIZATION = True
except ImportError:
    HAS_VISUALIZATION = False

console = Console()

# Command-specific directories
STATISTIC_INTER_DIR = config.inter_dir / "statistic"
DEFAULT_OUTPUT_DIR = Path("output/statistics")

def statistic(
    input_file: Path = typer.Argument(..., help="Path to CSV file generated by collect command"),
    output_dir: Path = typer.Option(DEFAULT_OUTPUT_DIR, help="Directory to store statistics and visualizations"),
    cwe_filter: Optional[List[str]] = typer.Option(None, help="Filter by CWE IDs (e.g. 79,89)"),
    project_filter: Optional[List[str]] = typer.Option(None, help="Filter by project types"),
    year_range: Optional[List[int]] = typer.Option(None, help="Filter by year range (e.g. 2020,2022)"),
    verbose: bool = typer.Option(False, help="Enable verbose output")
):
    """
    Generate statistics and visualizations from collected data.
    
    This command generates statistics and visualizations from the collected data,
    including trends over time, CWE distribution, and project type distribution.
    """
    # Enable verbose logging if requested
    Logger.set_verbose(verbose)
    
    # Check if visualization libraries are available
    if not HAS_VISUALIZATION:
        Logger.warning("Visualization libraries not found. Install matplotlib, pandas, and seaborn to enable visualizations.")
    
    # Start timing
    start_time = time.time()
    
    # Create output directory
    ensure_dir(output_dir)
    
    # Create intermediate directory
    ensure_dir(STATISTIC_INTER_DIR)
    
    # Read input file
    Logger.info(f"Reading input file: {input_file}")
    records = read_csv_file(input_file)
    
    if not records:
        Logger.error("No records found in input file")
        raise typer.Exit(1)
    
    # Apply filters
    filtered_records = _apply_filters(records, cwe_filter, project_filter, year_range)
    
    Logger.info(f"Generating statistics for {len(filtered_records)} records")
    
    # Generate statistics
    statistics = {
        "total_records": len(filtered_records),
        "cwe_distribution": _get_cwe_distribution(filtered_records),
        "project_type_distribution": _get_project_type_distribution(filtered_records),
        "yearly_distribution": _get_yearly_distribution(filtered_records),
        "top_repositories": _get_top_repositories(filtered_records)
    }
    
    # Save statistics
    stats_file = output_dir / "statistics.json"
    write_json_file(statistics, stats_file)
    Logger.success(f"Statistics saved to {stats_file}")
    
    # Generate visualizations if libraries are available
    if HAS_VISUALIZATION:
        _generate_visualizations(statistics, output_dir)
    
    # Report timing
    elapsed_time = time.time() - start_time
    Logger.info(f"Statistics generation completed in {elapsed_time:.2f} seconds")
    
    return statistics

def _apply_filters(records, cwe_filter, project_filter, year_range):
    """Apply filters to records."""
    filtered_records = records.copy()
    
    # Filter by CWE ID
    if cwe_filter:
        cwe_ids = [f"CWE-{cwe}" if not cwe.startswith("CWE-") else cwe for cwe in cwe_filter]
        filtered_records = [r for r in filtered_records if r.get("cwe_id") in cwe_ids]
        Logger.info(f"Filtered to {len(filtered_records)} records with CWE IDs: {', '.join(cwe_ids)}")
    
    # Filter by project type
    if project_filter:
        filtered_records = [r for r in filtered_records if r.get("project_type") in project_filter]
        Logger.info(f"Filtered to {len(filtered_records)} records with project types: {', '.join(project_filter)}")
    
    # Filter by year range
    if year_range and len(year_range) == 2:
        start_year, end_year = year_range
        filtered_records = [
            r for r in filtered_records 
            if r.get("cve_id", "").startswith(f"CVE-") and 
            start_year <= int(r.get("cve_id", "CVE-0000-0000").split("-")[1]) <= end_year
        ]
        Logger.info(f"Filtered to {len(filtered_records)} records from years {start_year}-{end_year}")
    
    return filtered_records

def _get_cwe_distribution(records):
    """Get CWE distribution."""
    cwe_counts = {}
    for record in records:
        cwe_id = record.get("cwe_id", "Unknown")
        cwe_counts[cwe_id] = cwe_counts.get(cwe_id, 0) + 1
    
    # Sort by count (descending)
    return dict(sorted(cwe_counts.items(), key=lambda x: x[1], reverse=True))

def _get_project_type_distribution(records):
    """Get project type distribution."""
    project_counts = {}
    for record in records:
        project_type = record.get("project_type", "Unknown")
        project_counts[project_type] = project_counts.get(project_type, 0) + 1
    
    # Sort by count (descending)
    return dict(sorted(project_counts.items(), key=lambda x: x[1], reverse=True))

def _get_yearly_distribution(records):
    """Get yearly distribution."""
    yearly_counts = {}
    for record in records:
        cve_id = record.get("cve_id", "")
        if cve_id.startswith("CVE-"):
            parts = cve_id.split("-")
            if len(parts) >= 2:
                year = parts[1]
                yearly_counts[year] = yearly_counts.get(year, 0) + 1
    
    # Sort by year
    return dict(sorted(yearly_counts.items()))

def _get_top_repositories(records):
    """Get top repositories."""
    repo_counts = {}
    for record in records:
        repo = record.get("repository", "")
        if repo:
            repo_counts[repo] = repo_counts.get(repo, 0) + 1
    
    # Sort by count (descending) and take top 10
    return dict(sorted(repo_counts.items(), key=lambda x: x[1], reverse=True)[:10])

def _generate_visualizations(statistics, output_dir):
    """Generate visualizations."""
    # Create visualization directory
    viz_dir = output_dir / "visualizations"
    ensure_dir(viz_dir)
    
    Logger.info("Generating visualizations")
    
    # Set style
    if HAS_VISUALIZATION:
        sns.set(style="darkgrid")
        
        # Yearly distribution
        plt.figure(figsize=(12, 6))
        years = list(statistics["yearly_distribution"].keys())
        counts = list(statistics["yearly_distribution"].values())
        plt.bar(years, counts, color='skyblue')
        plt.title('PHP Vulnerabilities by Year')
        plt.xlabel('Year')
        plt.ylabel('Number of Vulnerabilities')
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.savefig(viz_dir / "yearly_distribution.png", dpi=300)
        plt.close()
        
        # CWE distribution (top 10)
        plt.figure(figsize=(12, 6))
        top_cwes = list(statistics["cwe_distribution"].items())[:10]
        cwe_ids = [cwe[0] for cwe in top_cwes]
        cwe_counts = [cwe[1] for cwe in top_cwes]
        plt.barh(cwe_ids, cwe_counts, color='lightcoral')
        plt.title('Top 10 CWE Types')
        plt.xlabel('Number of Vulnerabilities')
        plt.ylabel('CWE ID')
        plt.tight_layout()
        plt.savefig(viz_dir / "cwe_distribution.png", dpi=300)
        plt.close()
        
        # Project type distribution
        plt.figure(figsize=(10, 8))
        project_types = list(statistics["project_type_distribution"].keys())
        project_counts = list(statistics["project_type_distribution"].values())
        plt.pie(project_counts, labels=project_types, autopct='%1.1f%%', startangle=90, shadow=True)
        plt.title('Project Type Distribution')
        plt.axis('equal')
        plt.tight_layout()
        plt.savefig(viz_dir / "project_type_distribution.png", dpi=300)
        plt.close()
        
        Logger.success(f"Visualizations saved to {viz_dir}")
    else:
        Logger.warning("Skipping visualizations: Required libraries not available") 