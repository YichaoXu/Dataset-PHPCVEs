"""
AI Reclassify command module for PHP CVE Dataset Collection Tool.

This module provides functionality to reclassify PHP projects based on README content
using AI models.
"""

import time
import json
import re
import requests
from pathlib import Path
from typing import Optional, Dict, Any
import typer
from rich.console import Console

from src.utils.logger import Logger
from src.utils.file_utils import ensure_dir, read_csv_file, write_csv_file
from src.utils.ui import ProgressUI
from src.config import INTER_DIR

console = Console()

# Command-specific directories
RECLASSIFY_INTER_DIR = INTER_DIR / "reclassify"

def reclassify(
    input_file: Path = typer.Argument(..., help="Path to CSV file generated by collect command"),
    output_file: Optional[Path] = typer.Option(None, help="Path to output CSV file (default: input file with _reclassified suffix)"),
    api_key: Optional[str] = typer.Option(None, help="API key for AI service"),
    model: str = typer.Option("gpt-3.5-turbo", help="AI model to use for classification"),
    force: bool = typer.Option(False, help="Force reclassification of all projects"),
    verbose: bool = typer.Option(False, help="Enable verbose output")
):
    """
    Reclassify PHP projects based on README content using AI.
    
    This command uses AI to analyze README files from GitHub repositories and
    reclassify PHP projects into more specific categories.
    """
    # Enable verbose logging if requested
    Logger.set_verbose(verbose)
    
    # Start timing
    start_time = time.time()
    
    # Set default output file if not provided
    if not output_file:
        output_file = input_file.with_stem(f"{input_file.stem}_reclassified")
    
    # Create intermediate directory
    ensure_dir(RECLASSIFY_INTER_DIR)
    
    # Read input file
    Logger.info(f"Reading input file: {input_file}")
    records = read_csv_file(input_file)
    
    if not records:
        Logger.error("No records found in input file")
        raise typer.Exit(1)
    
    # Check API key
    if not api_key:
        Logger.error("No API key provided. Set it with --api-key.")
        raise typer.Exit(1)
    
    # Process records
    Logger.info(f"Reclassifying {len(records)} projects")
    
    # Track statistics
    cache_hits = 0
    api_calls = 0
    format_errors = 0
    
    # Process each record
    with ProgressUI(len(records), "Reclassifying projects") as progress:
        for i, record in enumerate(records):
            cve_id = record.get("cve_id", f"Unknown-{i}")
            repo = record.get("repository", "")
            
            progress.update(0, f"{cve_id} ({repo})")
            
            try:
                # Skip if no repository
                if not repo:
                    progress.log_warning(f"Skipped {cve_id}: No repository information")
                    progress.update(1, cve_id)
                    continue
                
                # Get README content
                readme = _get_readme_content(repo, RECLASSIFY_INTER_DIR, force)
                
                if not readme:
                    progress.log_warning(f"Skipped {cve_id}: Could not retrieve README")
                    progress.update(1, cve_id)
                    continue
                
                # Check cache for classification
                cache_file = RECLASSIFY_INTER_DIR / f"{repo.replace('/', '_')}.json"
                
                if not force and cache_file.exists():
                    try:
                        with open(cache_file, 'r', encoding='utf-8') as f:
                            classification = json.load(f)
                            cache_hits += 1
                    except Exception:
                        classification = None
                else:
                    classification = None
                
                # Classify with AI if not in cache
                if not classification:
                    classification = _classify_with_ai(api_key, readme, repo, model)
                    api_calls += 1
                    
                    # Save to cache if successful
                    if classification:
                        with open(cache_file, 'w', encoding='utf-8') as f:
                            json.dump(classification, f)
                
                # Update record with classification
                if classification and "project_type" in classification:
                    old_type = record.get("project_type", "Unknown")
                    new_type = classification["project_type"]
                    confidence = classification.get("confidence", 0)
                    reasoning = classification.get("reasoning", "")
                    
                    # Add classification to record
                    record["ai_project_type"] = new_type
                    record["ai_confidence"] = confidence
                    record["ai_reasoning"] = reasoning
                    
                    if old_type != new_type:
                        progress.log(f"Reclassified {cve_id}: {old_type} -> {new_type} (confidence: {confidence}%)")
                    else:
                        progress.log(f"Confirmed {cve_id}: {old_type} (confidence: {confidence}%)")
                else:
                    format_errors += 1
                    progress.log_error(f"Failed to classify {cve_id}: Invalid response format")
            except Exception as e:
                progress.log_error(f"Error processing {cve_id}: {str(e)}")
            
            progress.update(1, cve_id)
    
    # Save updated records
    Logger.info(f"Saving {len(records)} records to {output_file}")
    write_csv_file(records, output_file)
    
    # Report statistics
    Logger.info(f"Cache hits: {cache_hits}")
    Logger.info(f"API calls: {api_calls}")
    Logger.info(f"Format errors: {format_errors}")
    
    # Report timing
    elapsed_time = time.time() - start_time
    Logger.info(f"Reclassification completed in {elapsed_time:.2f} seconds")
    Logger.success(f"Reclassified data saved to {output_file}")
    
    return len(records)

def _get_readme_content(repo_url: str, cache_dir: Path, force: bool = False) -> Optional[str]:
    """Get README content from GitHub repository."""
    # Extract owner and repo from URL
    repo_path = repo_url.replace("https://github.com/", "")
    parts = repo_path.split('/')
    if len(parts) < 2:
        Logger.warning(f"Invalid repository URL format: {repo_url}")
        return None
    
    owner, repo = parts[0], parts[1]
    
    # Check cache
    readme_cache = cache_dir / f"{owner}_{repo}_readme.txt"
    if not force and readme_cache.exists():
        try:
            with open(readme_cache, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception as e:
            Logger.warning(f"Failed to read cached README for {repo_url}: {str(e)}")
    
    # Download README
    try:
        url = f"https://raw.githubusercontent.com/{owner}/{repo}/master/README.md"
        response = requests.get(url, timeout=10)
        
        if response.status_code == 200:
            readme = response.text
            
            # Save to cache
            with open(readme_cache, 'w', encoding='utf-8') as f:
                f.write(readme)
            
            return readme
        
        # Try README.rst if README.md not found
        url = f"https://raw.githubusercontent.com/{owner}/{repo}/master/README.rst"
        response = requests.get(url, timeout=10)
        
        if response.status_code == 200:
            readme = response.text
            
            # Save to cache
            with open(readme_cache, 'w', encoding='utf-8') as f:
                f.write(readme)
            
            return readme
        
        # Try README if others not found
        url = f"https://raw.githubusercontent.com/{owner}/{repo}/master/README"
        response = requests.get(url, timeout=10)
        
        if response.status_code == 200:
            readme = response.text
            
            # Save to cache
            with open(readme_cache, 'w', encoding='utf-8') as f:
                f.write(readme)
            
            return readme
        
        return None
    except Exception as e:
        Logger.warning(f"Error downloading README for {repo_url}: {str(e)}")
        return None

def _classify_with_ai(api_key: str, readme: str, repo_url: str, model: str) -> Optional[Dict[str, Any]]:
    """Classify a project using AI based on README content."""
    # Prepare prompt
    prompt = f"""
    You are an expert in PHP projects classification. Please analyze the following README content from a PHP project and classify it into one of these categories:
    
    1. Web App - A complete web application
    2. Framework - A PHP framework for building applications
    3. Framework Plugin - A plugin for a PHP framework
    4. Framework Theme - A theme for a PHP framework
    5. Library - A reusable PHP library
    6. CLI App - A command-line PHP application
    7. PHP-SRC - PHP language source code
    
    Repository URL: {repo_url}
    
    README content:
    {readme[:4000]}  # Limit to 4000 chars to avoid token limits
    
    Respond with a JSON object containing:
    {{"project_type": "category_name", "confidence": 0-100, "reasoning": "brief explanation"}}
    """
    
    try:
        # Determine API endpoint based on model
        if "gpt" in model.lower():
            url = "https://api.openai.com/v1/chat/completions"
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}"
            }
            payload = {
                "model": model,
                "messages": [
                    {"role": "system", "content": "You are an expert in PHP project classification."},
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.2
            }
            
            response = requests.post(url, headers=headers, json=payload)
            
            if response.status_code == 200:
                result = response.json()
                content = result["choices"][0]["message"]["content"]
            else:
                Logger.error(f"API error: {response.status_code} - {response.text}")
                return None
                
        elif "deepseek" in model.lower():
            # DeepSeek API implementation
            url = "https://api.deepseek.com/v1/chat/completions"  # Replace with actual endpoint
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}"
            }
            payload = {
                "model": model,
                "messages": [
                    {"role": "system", "content": "You are an expert in PHP project classification."},
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.2
            }
            
            response = requests.post(url, headers=headers, json=payload)
            
            if response.status_code == 200:
                result = response.json()
                content = result["choices"][0]["message"]["content"]
            else:
                Logger.error(f"API error: {response.status_code} - {response.text}")
                return None
        else:
            Logger.error(f"Unsupported model: {model}")
            return None
        
        # Extract JSON from response
        json_match = re.search(r'({.*})', content, re.DOTALL)
        
        if json_match:
            try:
                return json.loads(json_match.group(1))
            except json.JSONDecodeError:
                Logger.warning(f"Failed to parse JSON response: {content}")
                return None
        else:
            Logger.warning(f"No JSON found in response: {content}")
            return None
    except Exception as e:
        Logger.error(f"API error: {str(e)}")
        return None 